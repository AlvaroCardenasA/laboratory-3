# -*- coding: utf-8 -*-
"""Laboratory3_syntaxError.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pX-amcst7vk_PckEaqhumMwmQ1VN6UVS

# Laboratory 3: Edge Detection
Finding edges in an image is one of the most fundamental image processing operations. Edges can provide clues about the elements and meaning of an image. Physically, an edge is the outside limit of an object, area, or surface. But, what is an edge inside a 2D image? They are significant local changes in the image where brightness changes dramatically. These changes represent the boundary between two or more materially distinct regions or physical surfaces.

Conversely, edge detection is a challenging task because edges are not always clear due to lightning and shadows. So, many methods were researched since the 80s. In this tutorial, you'll implement a preliminary set of edge detection methods which are based solely on filters. 

<img src='https://drive.google.com/uc?id=1HnxgN2sV0dhqkjklPkpEuoy51QR_T0Hx' width='40%'>

### Import resources and display image
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

import cv2
import numpy as np

# %matplotlib inline

# Read in the image
image = mpimg.imread('road.jpg')

# Convert to grayscale for filtering
gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

plt.imshow(gray, cmap='gray')

from google.colab import drive
drive.mount('/content/drive')

"""### Create a custom kernel and filter the image


"""

# Create a custom kernel

# 3x3 array for edge detection
sobel_x = np.array([[ -1, -2, -1], 
                   [ 0, 0, 0], 
                   [ 1, 2, 1]])

sobel_y = np.array([[-1, 0, 1], 
                   [ -2, 0, 2], 
                   [ -1, 0, 1]])


# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  
filtered_image = cv2.filter2D(gray, -1, sobel_x)

plt.imshow(filtered_image, cmap='gray')



"""## Exercise 1: 
Select an image and test out the filters explained in our last lecture 3: sobel x, sobel y, prewitt x, prewitt y. Display the filtering results as subplots with plt.subplots. 

Then, answer the following questions:
- Do you notice any result better than the others?
- Which of your filters perform better and why? 
- What happens if you try to implement any point processing method before? Does the result change? 

"""

img=cv2.imread('hous.jpg')
out = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
plt.title('Original')
plt.imshow(out)
plt.show()
#Filtering Sobel x
sobel_x = np.array([[ -1, -3, -1], 
                   [ 0, 0, 0], 
                   [ 1, 3, 1]])
sobelximage = cv2.filter2D(out, -1, sobel_x)
#Filtering Sobel y
sobel_y = np.array([[-1, 0, 1], 
                   [ -3, 0, 3], 
                   [ -1, 0, 1]])
sobelyimage = cv2.filter2D(out, -1, sobel_y)
#Filtering Prewitt x
prewitt_x=np.array([[ -1, -1, -1], 
                   [ 0, 0, 0], 
                   [ 1, 1, 1]])
prewittximage = cv2.filter2D(out, -1, prewitt_x)
#Filtering Prewitt y
prewitt_y=np.array([[-1, 0, 1], 
                   [ -1, 0, 1], 
                   [ -1, 0, 1]])
prewittyimage = cv2.filter2D(out, -1, prewitt_y)
#Filtering Laplacian
def laplacianna(s):
  if s=='one':
    filter = np.array([
    [0, 1, 0],
    [1, -4, 1],
    [0, 1, 0]])
  elif s == 'two':
    filter = np.array([
    [1, 1, 1],
    [1, -8, 1],
    [1, 1, 1]])
  elif s == 'two':
    filter = np.array([
    [2, -1, 2],
    [-1, -4, -1],
    [2, 1, 2]])
  elif s == 'four':
    filter = np.array([
    [-1, 2, -1],
    [2, -4, 2],
    [-1, 2, -1]])
  else:
    print('Not available option')
    filter=np.zeros([3,3])
  return filter
laplacian_filter=laplacianna('two') 
laplacianimage=cv2.filter2D(gray, -1, laplacian_filter)
#Filtering Robinson
def robinn(s):
  if s=='N':
    filter=np.array([[ -1, 0, 1], 
                   [ -2, 0, 2], 
                   [ -1, 0, 1]])
  elif s=='NE':
    filter=np.array([[ -2, -1, 0], 
                   [ -1, 0, 1], 
                   [ 0, 1, 2]])
  elif s=='E':
    filter=np.array([[ -1, -2, -1], 
                   [ 0, 0, 0], 
                   [ 1, 2, 1]])
  elif s=='SE':
    filter=np.array([[ 0, -1, -2], 
                   [ 1, 0, -1], 
                   [ 2, 1, 0]])
  elif s=='S':
    filter=np.array([[ 1, 0, -1], 
                   [ 2, 0, -2], 
                   [ 1, 0, -1]])
  elif s=='SW':
    filter=np.array([[ 2, 1, 0], 
                   [ 1, 0, -1], 
                   [ 0, -1, -2]])
  elif s=='W':
    filter=np.array([[ 1, 2, 1], 
                   [ 0, 0, 0], 
                   [ -1, -2, -1]])
  elif s=='NW':
    filter=np.array([[ 0, 1, 2], 
                   [ -1, 0, 1], 
                   [ -2, -1, 0]])
  else:
    print('Not available option')
    filter=np.zeros([3,3])
  return filter
robinson_filter=robinn('SW') 
robinsonimage=cv2.filter2D(gray, -1, robinson_filter)

#Filtering Krisch
def krischs(s):
  if s=='N':
    filter=np.array([[ -3, -3, 5], 
                   [ -3, 0, 5], 
                   [ -3, -3, 5]])
  elif s=='NE':
    filter=np.array([[ -3, -3, -3], 
                   [ -3, 0, 5], 
                   [ -3, 5, 5]])
  elif s=='E':
    filter=np.array([[ -3, -3, -3], 
                   [ -3, 0, -3], 
                   [ 5, 5, 5]])
  elif s=='SE':
    filter=np.array([[ -3, -3, -3], 
                   [ 5, 0, -3], 
                   [ 5, 5, -3]])
  elif s=='S':
    filter=np.array([[ 5, -3, -3], 
                   [ 5, 0, -3], 
                   [ 5, -3, -3]])
  elif s=='SW':
    filter=np.array([[ 5, 5, -3], 
                   [ 5, 0, -3], 
                   [ -3, -3, -3]])
  elif s=='W':
    filter=np.array([[ 5, 5, 5], 
                   [ -3, 0, -3], 
                   [ -3, -3, -3]])
  elif s=='NW':
    filter=np.array([[ -3, 5, 5], 
                   [ -3, 0, 5], 
                   [ -3, -3, -3]])
  else:
    print('Not available option')
    filter=np.zeros([3,3])
  return filter
krisch_filter=krischs('NW')
krischimage= cv2.filter2D(gray, -1, krisch_filter)

#printing 
f, ((ax1, ax2), (ax3, ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4, 2,figsize=(15,15))

#original
ax1.set_title('Original')
ax1.imshow(gray,cmap='gray')

#sobel x filter
ax2.set_title('Sobel x')
ax2.imshow(sobelximage,cmap='gray')

#sobel y filter
ax3.set_title('Sobel y')
ax3.imshow(sobelyimage,cmap='gray')

#Prewitt x filter
ax4.set_title('Prewitt x')
ax4.imshow(prewittximage,cmap='gray')

#prewitt y filter
ax5.set_title('Prewitt y')
ax5.imshow(prewittyimage,cmap='gray')

#laplacian filter
ax6.set_title('Laplacian')
ax6.imshow(laplacianimage,cmap='gray')

#Robinson filter
ax7.set_title('Robinson filter')
ax7.imshow(robinsonimage,cmap='gray')

#Krisch filter
ax8.set_title('Krisch filter')
ax8.imshow(krischimage,cmap='gray')

"""**Do you notice any result better than the others?**

In the different filters made, including sobel x, sobel y, prewitt x and prewitt, and in the image selected for the different filters, an improvement was noted in the Krisch Filter on the visualization of the white lines, although with noise, which is noticeable. Lots of white dots and gap fill with no curves or lines, but speaking of just borders or lines display the Robinson Filter is a better exponent of borders and with very little noise.

**Which of your filters perform better and why?**

It is clearly noticeable that it works better with the Robinson Filter because a better black background is noticeable and the border lines are more pronounced and it has little noise in the fills compared to the others, although it is a little more elaborate in the matrices since they are taken a mask of the 8 main directions as north, northeast, west, south west, south, southeast, east, more east although these masks would show different filters in this particular image which if it has more lines it looks better than the other filters .

**What happens if you try to implement any point processing method before? Does the result change?**
"""

import pylab
def convolve (img, fil, mode = 'same'): 
    if mode == 'fill':
        h = fil.shape[0] // 2
        w = fil.shape[1] // 2
        img = np.pad(img, ((h, h), (w, w),(0, 0)), 'constant')
        conv_b = _convolve(img[:,:,0],fil) 
        conv_g = _convolve(img[:,:,1],fil)
        conv_r = _convolve(img[:,:,2],fil)
        dstack = np.dstack ([conv_b, conv_g, conv_r]) 
        return dstack 
def _convolve(img,fil):         
         fil_heigh = fil.shape [0] 
         fil_width = fil.shape [1] 
         conv_heigh = img.shape [0] -fil.shape [0] + 1 
         conv_width = img.shape[1] - fil.shape[1] + 1
         conv = np.zeros((conv_heigh,conv_width),dtype = 'uint8')
         for i in range(conv_heigh):
          for j in range (conv_width):
              conv[i][j] = wise_element_sum(img[i:i + fil_heigh,j:j + fil_width ],fil)
         return conv
    
def wise_element_sum(img,fil):
    res = (img * fil).sum() 
    if(res < 0):
        res = 0
    elif res > 255:
        res  = 255
    return res
img = plt.imread ("image.jpg") 
pylab.show()
fil = np.array([[-1,-1,-1, 0, 1],
                [-1,-1, 0, 1, 1],
                [-1, 0, 1, 1, 1]])
res = convolve(img,fil,'fill')
print("img shape :" + str(img.shape))
plt.imshow (res)
print("res shape :" + str(res.shape))
plt.imsave("res.jpg",res)
pylab.show()
#Filtering Robinson
def robinn(s):
  if s=='SE':
    filter=np.array([[ 0, -1, -2], 
                   [ 1, 0, -1], 
                   [ 2, 1, 0]])
  else:
    print('Not available option')
    filter=np.zeros([3,3])
  return filter
robinson_filter=robinn('SE') 
robinsonimage=cv2.filter2D(res, -1, robinson_filter)
f, (ax2) = plt.subplots(1, figsize=(6,5)) 
ax2.set_title('Robinson Filter')
plt.imshow(robinsonimage, cmap = 'gray')
plt.show()

"""**Does the result change?**

By performing a point processing method before applying a filter it is clear that this new processed image shows much better defined edges and less noise in the fills. For this step, a Robinson Filter was used, which offers us different faces and for this specific point, the southeast face of the image was used, since it shows us a better result than the other filters.

## Exercise 2: 

So far, you learned to use cv2.filter2D to apply a convolution to an image, however, you also need to understand the internals of this method. Then, you will have to implement a function to apply convolutions by passing an image, a kernel, the padding, and the stride. Consider using notebook forms to change the parameters easily. 

Apply your function to the same image with the sobel x, sobel y, prewitt x, prewitt y filters, and answer the following question: 
- Are the filter's performance similar to the previous results? Have you run into any problem in the implementation? 

Try to be thoughtful in your analysis. You'll have to copy your answers into the tutorial form.
"""

#CONVOLUTION
import matplotlib.pyplot as plt
import pylab
import numpy as np
 
def convolve (img, fil, mode = 'same'): # three channels detached
 
    if mode == 'fill':
        h = fil.shape[0] // 2
        w = fil.shape[1] // 2
        img = np.pad(img, ((h, h), (w, w),(0, 0)), 'constant')
        conv_b = _convolve(img[:,:,0],fil) # start convolution
        conv_g = _convolve(img[:,:,1],fil)
        conv_r = _convolve(img[:,:,2],fil)
 
        dstack = np.dstack ([conv_b, conv_g, conv_r]) # Combine the three channels after convolution
        return dstack #Return after convolution
def _convolve(img,fil):         
    
         fil_heigh = fil.shape [0] # Get the height of the convolution filter
         fil_width = fil.shape [1] # Get the width of the convolution filter
    
         conv_heigh = img.shape [0] -fil.shape [0] + 1 # Size of the convolution
         conv_width = img.shape[1] - fil.shape[1] + 1
 
         conv = np.zeros((conv_heigh,conv_width),dtype = 'uint8')
    
         for i in range(conv_heigh):
          for j in range (conv_width): # Multiply by point (convolution), then add to get each point following the formula
              conv[i][j] = wise_element_sum(img[i:i + fil_heigh,j:j + fil_width ],fil)
         return conv
    
def wise_element_sum(img,fil):
    res = (img * fil).sum() 
    if(res < 0):
        res = 0
    elif res > 255:
        res  = 255
    return res

img = plt.imread ("photo.jpg") 
 
plt.imshow (img) 
pylab.show()
 
 
 # odd rows and columns
fil = np.array([[-1,-1,-1, 0, 1],
                [-1,-1, 0, 1, 1],
                [-1, 0, 1, 1, 1]])
 
res = convolve(img,fil,'fill')
print("img shape :" + str(img.shape))
plt.imshow (res) #image show after convolution
print("res shape :" + str(res.shape))
plt.imsave("res.jpg",res)
pylab.show()

import cv2
sobelx=cv2.Sobel(img,cv2.CV_8U,1,0,ksize=3)
sobely=cv2.Sobel(img,cv2.CV_8U,0,1,ksize=3)
plt.imshow (sobelx, cmap='gray')
pylab.show()
plt.imshow (sobely, cmap='gray')
pylab.show()

kernelX=np.array([[1,1,1],[0,0,0],[-1,-1,-1]])
kernelY=np.array([[-1,0,1],[-1,0,1],[-1,0,1]])
PrewittX=cv2.filter2D(img,-1,kernelX)
PrewittY=cv2.filter2D(img,-1,kernelY)
plt.imshow (PrewittX, cmap='gray')
pylab.show()
plt.imshow (PrewittY, cmap='gray')
pylab.show()

"""#Answer
#Are the filter's performance similar to the previous results? Have you run into any problem in the implementation?

The filtering done in sobel x, sobel y, prewitt x, prewitt y filters does not have the same quality or sharpness as the initial code-based convolution filtering because in code-based convolution filtering you can see the smallest details of each line that defines each object that can be seen in the image, that is, from the cloud, the reflections in the river, the banks of the river, the details in each tree and each hill, all that is noticeable and can be distinguished without there being places with fuzzy spots. On the other hand, in the convolution carried out in sobel x, sobel y, prewitt x, prewitt y, there are lack of details, low sharpness and lack of brightness to be able to detect aspects of each object in the image.
"""